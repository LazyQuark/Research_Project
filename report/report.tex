\documentclass[a4paper,11pt]{article}


\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[margin = 1in]{geometry}
\usepackage{graphicx}
\usepackage{hyperref}

\title{\textbf{Research Project I} \\[0.5cm]
\large INDIAN INSTITUTE OF SCIENCE EDUCATION AND RESEARCH KOLKATA}


\author{KONDAPALLI VARA PRASAD \\ 22MS161 \\[0.5cm]
\textbf{Supervisor:} Rajesh Kumble Nayak}
\date{}


\begin{document}
\maketitle
\tableofcontents
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Gravitational waves are waves of the intensity of gravity generated by the accelerated masses of an orbital binary system that propagate as waves outward from their source at the speed of light
Gravitational waves transport energy as gravitational radiation, a form of radiant energy similar to electromagnetic radiation. Newton's law of universal gravitation, part of classical mechanics, does not provide for their existence, since that law is predicated on the assumption that physical interactions propagate instantaneously
The first indirect evidence for the existence of gravitational waves came in 1974 from the observed orbital decay of the Hulseâ€“Taylor binary pulsar, which matched the decay predicted by general relativity as energy is lost to gravitational radiation. In 1993, Russell A. Hulse and Joseph Hooton Taylor Jr. received the Nobel Prize in Physics for this discovery.

Direct observation of gravitational waves was not made until 2015, when a signal generated by the merger of two black holes was received by the LIGO gravitational wave detectors in Livingston, Louisiana, and in Hanford, Washington.
In gravitational-wave astronomy, observations of gravitational waves are used to infer data about the sources of gravitational waves. Sources that can be studied this way include binary star systems composed of white dwarfs, neutron stars, and black holes; events such as supernovae; and the formation of the early universe shortly after the Big Bang.



\pagebreak
\section{Paper:I}
\begin{center}
      INTRODUCTION TO ANALYSIS OF LOW-FREQUENCY GRAVITATIONAL WAVE DATA by 
 B. F. Schutz
\end{center}

\subsection{Intro :}
 To recognize and extract the signals, one must apply special computer operations, called filters, to the
 data to remove the noise and retain the signal. Filters are constructed from theoretical expectations of
 what the wave form looks like. A  filter that is known to most physicists, and which
 provides a simple example of the principle of filtering, is the Fourier transform. If one expects the data
 to contain a simple signal of constant but unknown
 frequency, then the Fourier transform is the ideal filter to use to find it. Even if, in the time-series data,
 the signal amplitude is too small to be seen against
 noise, the Fourier transform allows one to identify the
 signal: it rearranges the data in such a way that the
 noise is spread over the whole spectrum but the power
 in the signal is concentrated at one frequency. After
 applying this filter, the ratio of the signal's Fourier
 amplitude to the standard deviation of the noise at
 nearby frequencies can be very large. Moreover, the
 filter has given us additional information about the
 signal: its amplitude, frequency, and phase, all of
 which can be regarded as parameters of the expected
 signal waveform that we wanted to determine.

  We do expect constant-frequency sources,
 such as binary systems, but the motion of the detector as it orbits the Sun imposes a Doppler shift on the
 incoming wave. In the data itself, no physical signal
 will remain of constant frequency. Moreover, many
 other sources, such as the coalescences of supermassive black hole binaries, produce more complicated
 signals whose frequencies depend on time in a predictable way.


\section{Content :}

In this analysis the primary problem is to identify the gravitational waveform that is hidden in the noise.
One intutive way is to check for the signals that we are sure that it cannot be produced by noises in the time series data if we are unsure of the waveform.
It is possible to recognize much weaker signals if we know what the waveform looks like but still the parameters that define the waveform need to be known simultaneously.
Since the data has noises all over the detection of signal is based on probabilities, we need to assess this probability to have some confidence in our detection 
Every signal should be defined before the analysis begins. In some cases, the definition is very precise, such as that the signal must
look like that expected from a coalescing black-hole binary with some range of parameters.

In other case it might be the signal should be a arbitrary waveform that is so rare that it appears in the time series data not more than once in 10$^4$ years.
 It is important to define before the experiment what data sequences will be regarded as signals,
 so that their probabilities can be unambiguously calculated. Even if the criterion is crude, to allow one to discover unexpected
 waveforms, one must define the criterion and calculate the chances of random noise satisfying it. If this
 is not done, then one runs the risk of not being able
 to decide the significance of an observation.

x$_j$ denotes a sample of the experimental data (the random variable),
 and $\mathbf{x}$ =(x$_0$,x$_1$,...,x$_{N-1}$) denotes the entire data set
 of N samples, which is called the stochastic process.
 The expected signal will be denoted by h$_j$ and the
 noise (which would be the output in the absence of a
 signal) is called n$_j$. Sums, where no limits are indicated, always run from 0 to N-1.
 In general the sample points follow a distribution function pdf: $p$($x$). 
















































































\end{document}